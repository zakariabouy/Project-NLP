{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf899e45",
   "metadata": {},
   "source": [
    "* * *\n",
    "<pre> INSEA                <i> Projet Statistiques Multivariées - 2025 </i></pre>\n",
    "* * *\n",
    "\n",
    "\n",
    "<pre align=\"left\"> Mardi 4 Novembre  2025             <i> Author: Hicham Janati </i></pre>\n",
    "* * *\n",
    "\n",
    "Consignes:\n",
    "----------\n",
    "- Deadline: *Dimanche 7 Décembre 23h59* | tout retard d'1h = -1\n",
    "- Tout travail doit être effectué par groupe de deux sans exception.\n",
    "- Il faut nommer le fichier avec le numéro du groupe seulement `groupe_X.ipynb` pas de noms. \n",
    "- PAS DE PDF NI DE FICHIER WORD. UN NOTEBOOK UNIQUEMENT.\n",
    "- Les noms des membres du groupe sont à mentionner en modifiant la ligne suivante:\n",
    "\n",
    "Membre 1:\n",
    "\n",
    "Membre 2:\n",
    "\n",
    "- Ce notebook contient 15 questions.\n",
    "- Il faut executer tout le notebook (Run all cells) avant de l'envoyer: vérifier que les cellules sont exécutées dans le bon ordre et qu'il n'y a pas d'erreur, je ne vais pas débugger votre code. \n",
    "- Le code doit être propre et lisible et surtout comprendre ce qu'il fait par tous les membres du groupe.\n",
    "- LIVRAISON UNIQUEMENT SUR DROPBOX (TOUT FICHIER ENVOYE PAR MAIL NE SERA PAS OUVERT):\n",
    "\n",
    "https://www.dropbox.com/request/bs2Tafzm0Bzr7rroAGtc\n",
    "\n",
    "Vous pouvez effectuer plusieurs uploads, seule la date la plus récente sera corrigée.\n",
    "\n",
    "- Le but n'est pas de produire du code qui marche: le but est de comprendre et maîtriser les mécanismes derrière et savoir utiliser quoi et quand. Ce notebook est loin d'être self-contained, cherchez, lisez et apprenez à devenir auto-didacte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4ebe82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f292b97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35d2f782",
   "metadata": {},
   "source": [
    "# Partie 1: Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6afb9",
   "metadata": {},
   "source": [
    "Les données sont coupés en deux: train et test. Il s'agit d'une liste d'SMS avec leur labels (Y) spam / non spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0803e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "X_train = np.load(\"data/X_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"data/X_test.npy\", allow_pickle=True)\n",
    "Y_train = np.load(\"data/Y_train.npy\", allow_pickle=True)\n",
    "Y_test = np.load(\"data/Y_test.npy\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de7e12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Play w computer? Aiyah i tok 2 u lor?',\n",
       "        \"Well there's not a lot of things happening in Lindsay on New years *sighs* Some bars in Ptbo and the blue heron has something going\",\n",
       "        'Dear are you angry i was busy dear',\n",
       "        \"Carlos'll be here in a minute if you still need to buy\"],\n",
       "       dtype=object),\n",
       " array([0, 0, 0, 0]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:4], Y_train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5e565",
   "metadata": {},
   "source": [
    "On rappelle que les données de `test` doivent être utilisées pour évaluer le modèle final comme si elles étaient nouvelles en production -- non disponibles à l'entraînement -- toute opération d'apprentissage (y compris la validation croisée) doit être faite sur les données `train` uniquement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3366050",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "En utilisant ```CountVectorizer``` de ```scikit-learn``` transformez les données. Quelle est l'utilité de cette opération ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80cb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec= vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f8bab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a4a093b",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "On modélise les données de chaque classe par une loi multinomiale. En utilisant ```MultinomialNB``` de scikit-learn, fittez un modèle et évaluez sa performance en calculant les scores de précision et de rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3509eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation de performance du modele MultinomialNB:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2413\n",
      "           1       0.97      0.89      0.93       373\n",
      "\n",
      "    accuracy                           0.98      2786\n",
      "   macro avg       0.97      0.94      0.96      2786\n",
      "weighted avg       0.98      0.98      0.98      2786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vec, Y_train)\n",
    "y_pred_mnb = mnb.predict(X_test_vec)\n",
    "\n",
    "\n",
    "print('Evaluation de performance du modele MultinomialNB:\\n')\n",
    "print(f'Classification Report:\\n{classification_report(Y_test, y_pred_mnb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a3d7d",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "Implémentez votre propre modèle naive bayes multinomial en utilisant numpy. Comparez avec scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3dfadb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2455327559.py, line 9)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class MymultinomialNB:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_log_prior_ = None\n",
    "        self.feature_log_prob_ = None\n",
    "        self.classes_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3034ba",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "Afin de comparer avec d'autres modèles qui s'attendent à des inputs continus, on peut utiliser des fréquences de mots au lieu du nombre brut. Appliquez la transformation `TfIdf` de scikit-learn sur les données. Fittez des modèles différents: LDA, régression logistique, QDA et SVM. Essayez de battre la performance du MulinomialNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8d576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b781aa",
   "metadata": {},
   "source": [
    "### Question 5:\n",
    "Visualisez la PCA et tSNE des données transformées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff86c4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c872a753",
   "metadata": {},
   "source": [
    "# Partie II: Introduction au NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47767fe",
   "metadata": {},
   "source": [
    "Dans cette partie on utilise des transformations plus avancées basées sur la factorisation matricielle. L'un des premiers modèles à grand succès pour représenter les mots est `Word2Vec`. Étant donné un vocabulaire de taille V, on peut représenter un input par un vecteur binaire de taille V (one-hot encoding). Par exemple si le vocabulaire est\n",
    "```[\"rouge\", \"chat\", \"souris\", \"courir\", \"mange\", \"ordinateur\", \"la\", \"le\", ...]``` \n",
    "Alors on peut représenter chaque mot par son vecteur one-hot de taille V:\n",
    "- \"chat\" -> [0, 1, 0, 0, 0, ...]\n",
    "- \"ordinateur\" -> [0, 0, 0, 0, 0, 1, 0, ...]\n",
    "\n",
    "La phrase \"le chat mange la souris\" peut être représentée par [0, 1, 1, 0, 1, 0, 1, 1, ...].\n",
    "\n",
    "On construit un réseau de neurones simple capable de prédire le mot manquant au milieu d'une phrase avec des données comme:\n",
    "- \"le chat la souris\" -> \"mange\"\n",
    "- \"la matrice est pas inversible\" -> \"n'\" \n",
    "...\n",
    "Ainsi, l'input du réseau doit être un vecteur de taille V. L'output doit être également **un vecteur de probabilités** de taille V. On prédit le mot avec la plus grande probabilité.\n",
    "\n",
    "On considère un réseau de neurones à une couche cachée de dimension M (M neurones). Le réseau de neurones doit en sortie prédire un mot caché. Soit $x \\in \\mathbb R^V$ un one-hot vecteur. Le réseau de neurones peut être défini formellement comme suit. Soit $W_{in} \\in \\mathbb{R}^{V \\times M}$ et $W_{out} \\in \\mathbb{R}^{M \\times V}$. \n",
    "\n",
    "$$ g(x) = W_{out}(W_{in}x) \\in \\mathbb R^{V} $$\n",
    "\n",
    "Pour obtenir un vecteur output positif et sommant à 1 (des probabilités sur les mots), on applique la fonction softmax:\n",
    "$$ softmax: z \\in \\mathbb R^V \\mapsto \\left[\\frac{e^{z_1}}{\\sum_j e^{z_j}}, \\dots, \\frac{e^{z_V}}{\\sum_j e^{z_j}}  \\right]^\\top$$\n",
    "\n",
    "Ainsi on définit: $ neuralnet(x) = softmax(g(x))$ et on entraîne le modèle avec la loss cross-entropy.\n",
    " \n",
    "Après avoir entraîné le modèle, les ligne de la matrice $W_{in}$ sont les embeddings des mots du vocabulaire.\n",
    "\n",
    "\n",
    "On commence par télécharger le modèle word2vec (peut prendre du temps):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3818bbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10054] Une connexion existante a dû être fermée par l’hôte distant>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1303\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1302\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1349\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1348\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1298\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1058\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1061\u001b[39m \n\u001b[32m   1062\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:996\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    995\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1475\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1473\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1475\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:517\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    512\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    513\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    514\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1103\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1382\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1381\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[38;5;28mself\u001b[39m._sslobj.do_handshake()\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mConnectionResetError\u001b[39m: [WinError 10054] Une connexion existante a dû être fermée par l’hôte distant",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapi\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m word2vec = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword2vec-google-news-300\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CE PC\\Project-NLP-2025\\.venv\\Lib\\site-packages\\gensim\\downloader.py:496\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, return_path)\u001b[39m\n\u001b[32m    494\u001b[39m path = os.path.join(folder_dir, file_name)\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(folder_dir):\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_path:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CE PC\\Project-NLP-2025\\.venv\\Lib\\site-packages\\gensim\\downloader.py:396\u001b[39m, in \u001b[36m_download\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    394\u001b[39m fname = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{fname}\u001b[39;00m\u001b[33m.gz\u001b[39m\u001b[33m\"\u001b[39m.format(fname=name)\n\u001b[32m    395\u001b[39m dst_path = os.path.join(tmp_dir, fname)\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _calculate_md5_checksum(dst_path) == _get_checksum(name):\n\u001b[32m    398\u001b[39m     sys.stdout.write(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:241\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    226\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    242\u001b[39m     headers = fp.info()\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:1391\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:1351\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1348\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1349\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1352\u001b[39m     r = h.getresponse()\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [WinError 10054] Une connexion existante a dû être fermée par l’hôte distant>"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "word2vec = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbabe3a",
   "metadata": {},
   "source": [
    "word2vec est n'est qu'un dictionnaire spécial \"mot\" -> vecteur:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b64da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec[\"computer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcecdc8",
   "metadata": {},
   "source": [
    "On peut obtenir l'embedding de plusieurs mots directement dans une liste. L'embedding d'une phrase est souvent défini comme la moyenne des embeddings de ses mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f8d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec[[\"computer\", \"mouse\", \"keyboard\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a273ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec[[\"I\", \"love\", \"computers\"]].mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6fc08",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Pour appliquer word2vec aux SMS, il faut d'abord les découper en mots. Implémentez une fonction naïve qui transforme un SMS en liste de mots ou _tokens_. C'est ce qu'on appelle un tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05f7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f73641d4",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "On peut vérifier si un mot fait partie du vocabulaire avec le test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32398c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"computer\" in word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9090ca6",
   "metadata": {},
   "source": [
    "Proposez une solution pour appliquer word2vec aux données SMS. Est-il meilleur comme embedding comparé au `CountVectorizer` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e9ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be090b85",
   "metadata": {},
   "source": [
    "`Word2vec` (2013) est l'un des premiers modèles de représentation vectorielle du langage naturel. L'une de ses limitations principales est le fait de ne pas pouvoir représenter des mots (ou bouts de mots) non-vus lors de l'entraînement. Quelques années plus tard, plusieurs avancées ont été introduites pour y remédier:\n",
    "\n",
    "### 1) Améliorer la tokenization:\n",
    "1. Au lieu de considérer un vocabulaire avec des mots, on considère un vocabulaire avec les mots, et les bouts de mots (ngrams):\n",
    "\n",
    "    \"diagonalisation matricielle\" -> \"diagonal\", \"isation\", \" \", \"matric\", \"ielle\". \n",
    "\n",
    "    Ceci est utilisé dans le modèle `fastText` (2016) dont l'architecture est similaire à celle de Word2Vec.\n",
    "\n",
    "2. WordPiece: approche bottom-up où le vocabulaire des tokens est construit en mergeant les caractères (a-Z, 0-9, symboles et ponctuation) + Ajouter des tokens spéciaux \"[UNK]\" (unknow) pour gérer les tokens non-vus, \"[SEP]\" (séparateur entre phrases ou textes), \"[MASK]\" (token qui veut dire \"ce mot est à prédire\") etc. Ce tokenizer est utilisé dans l'un des premiers modèles basés sur l'architecture Transformer (BERT) (2018).\n",
    "\n",
    "3. Byte-pair encoding (BPE): similaire à WordPiece mais à l'échelle du byte.  Ceci permet d'encoder n'importe quel string dans n'importe quelle langue: mots rares, typos, emojis, kanji... C'est le tokenizer adopté par l'un des fameux modèles de traduction à l'époque (Neural Machine Translation -- NMT 2015) pour traduire les mots rares; et ensuite par les modèles GPT (2018). Avec BPE, on n'a plus besoin du token spécial _unknown_ [UNK]. Vous pouvez voir comment le texte est tokenisé par GPT en visitant https://platform.openai.com/tokenizer. \n",
    "\n",
    "### 2) Améliorer l'architecture\n",
    "\n",
    "1. Limites de Word2Vec et companie:\n",
    "\n",
    "La nature des données de langage est séquentielle (comme les séries temporelles, mot après mot..), or les modèles comme Word2Vec et ses variantes (Fasttext, GloVe) ne prennent pas en considération l'ordre des mots: ils sont appliqués à des _bag of words_. En plus, même si ses modèles utilisent le contexte voisin, après l'entraînement, l'embedding d'un mot est le même quelque soit son contexte ce qui limite la compréhension des différentes nuances d'un même mot. \n",
    "\n",
    "2. Recurrent Neural Networks:\n",
    "\n",
    "L'architecture des réseaux de neurones récurrents (RNN) et ses variantes (LSTM, GRU) développés principalement dans les années 1990 sont revisités en (2013-2020) après le succès du deep learning (2012+) avec la réalisation de la grande puissance de calcul des GPUs. Ils permettent de prendre en considération l'aspect temporel des données mais restent difficiles à entraîner (nécessitent beaucoup de temps + instabilité des gradients). \n",
    "\n",
    "3. Transformers (en très bref):\n",
    "\n",
    "En 2017, l'architecture des Transformers est introduite. Son avantage principal est son formalisme matriciel qui est beaucoup plus parallélisable que les RNNs, et donc permet d'entraîner des modèles plus grands sur des données beaucoup plus grandes. Prenons le cas d'une architecture générative (GPT). Un transformer définit une structure appelée _Self-Attention Head_ qui fonctionne comme suit.\n",
    "Étant donnés les embeddings (statiques comme ceux de Word2Vec) des tokens d'une phrase, le mécanisme d'attention consiste à calculer des scores de similarités (produits scalaires) entre chaque paire d'embeddings, ceci permet d'obtenir une matrice de scores \"d'attention\" entre les tokens.\n",
    "\n",
    "Par exemple, pour une phrase \"Il me faut un tapis pour la souris Logitec\", l'embedding du mot \"souris\" sera pondéré par ses scores de similarité avec chacun des autres mots [\"Il\", \"me\", \"faut\", \"un\", \"tapis\", \"pour\", \"la\", \"logitec\"]. Ainsi, l'embedding d'un même mot dépend du contexte. Ceci permettra de distinguer la souris (animal) de la souris d'ordinateur.\n",
    "\n",
    " Ceci reste une explication très simpliste du mécanisme d'attention, pour visualiser le concept, regardez la vidéo de 3b1b https://www.youtube.com/watch?v=eMlx5fFNoYc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5a415",
   "metadata": {},
   "source": [
    "## III Partie 3 - Embeddings basés sur les transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf35bb",
   "metadata": {},
   "source": [
    "Dans cette partie, on passe à l'artillerie lourde: embeddings basés sur les transformers. On utilise ceux de BERT plutôt que GPT car BERT a été conçu pour la classification supervisée alors que GPT pour la génération de texte: l'embedding de BERT est plus pertinent pour notre problématique.\n",
    "\n",
    "On commence par tokeniser les données. Voici ce que donne le tokenizer avec une phrase par exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71330dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hey, are you free tomorrow at 8 ? gotta catch up bud.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2aec4",
   "metadata": {},
   "source": [
    "Le modèle BERT en revanche ne s'attend pas à des tokens en texte, mais aux token_ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hey, are you free tomorrow at 8 ? gotta catch up bud\"\n",
    "token_ids = tokenizer(text, return_tensors=\"pt\")\n",
    "token_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5213c82",
   "metadata": {},
   "source": [
    "On fait appel ensuite au modèle BERT. On peut voir les composants de son architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model.eval()\n",
    "bert_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07b8ac",
   "metadata": {},
   "source": [
    "On applique le modèle aux token_ids sans calcul de gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482197eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(**token_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611fe03",
   "metadata": {},
   "source": [
    "On peut accéder aux embeddings en cherchant la dernière couche cachée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86436f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bfc99",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "Expliquez la dimension obtenue de ces embeddings. On souhaite obtenir les embeddings de toutes les données directement. Appliquez la tokenization à la liste de textes suivante. Quel problème se pose ? Comment y remédier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"Hey, are you free tomorrow at 8 ? gotta catch up bud.\", \"Sure thing, let's go.\"]\n",
    "token_ids = tokenizer(texts, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfec6a8",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "Après avoir fixé le problème, analysez les tokens obtenus et le `attention_mask` de l'output. Comment peut-on savoir où le `padding` a été appliqué ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669b170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6225300c",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "L'embedding d'une phrase est la moyenne des embeddings de ses tokens. Appliquez BERT à une liste des donnés spams (X_train[:10]). Calculez le temps pris par cette opération en utilisant la librairie `time`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4020d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "713b2079",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "Avec une GPU, ce calcul peut être jusqu'à 100x fois plus rapide. On vous fournit les embeddings des données `X_train` et `X_test` calculés avec BERT. Refaire l'étape de visualisation et classification avec ces embeddings pour comparer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_bert = np.load(\"data/embeddings_train.npy\")\n",
    "X_test_bert = np.load(\"data/embeddings_test.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b87e89",
   "metadata": {},
   "source": [
    "# IV Partie 4: Data drift \n",
    "En production, les données nouvelles peuvent devenir de plus en plus différentes des données d'entraînement avec le temps: on parle de _data drift_ ou de _distribution shift_. Il faut alors réentraîner le modèle sur des données plus récentes. \n",
    "\n",
    "\n",
    "### Question 12\n",
    "Appliquez une PCA pour la réduire et implémentez un test statistique pour comparer les moyennes des embeddings Train et Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f925f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea6f3976",
   "metadata": {},
   "source": [
    "### Question 13\n",
    "En pratique, comparer les moyennes des distributions n'est pas suffisant pour détecter le drift. Si on obtient les vrais labels (même avec un petit retard), alors  on peut calculer les métriques de performances (précision, rappel) au cours du temps. Sinon, on peut chercher à prédire si un échantillon vient du train ou du test ! L'idée est: si un modèle ML est capable de les distinguer: il y a forcément un drift. Trouvez le meilleur modèle capable de le faire en utilisant les embeddings de BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65a5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85f8c015",
   "metadata": {},
   "source": [
    "## V Partie 5: Modélisation non supervisée\n",
    "\n",
    "#### Question 14\n",
    "Sans utiliser les labels, modéliser en utilisant le modèle GMM de `scikit-learn` les données (BERT embeddings + PCA) en utilisant quelques modèles différents (nombre de composantes 2 vs 3 -- et type de covariance). Comparez les performances avec les vrais labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc5024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5bf8af",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "Comparez ces modèles en utilisant le test du rapport de vraisemblance. Quel est le modèle plausible le plus simple ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb29db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
